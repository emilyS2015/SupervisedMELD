{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(123)\n",
    "vars=np.random.choice(40,10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  6, 10, 12, 38,  5, 11, 23,  1, 13, 20])"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(0,vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "np.random.seed(99)\n",
    "ab = itertools.chain(list(zip(np.random.dirichlet([1,1],15).tolist(),np.random.dirichlet([1,1],15).tolist())),\n",
    "                     list(zip(np.random.dirichlet([1,1,1],5).tolist(),np.random.dirichlet([1,1,1],5).tolist())), \n",
    "                     list(zip(np.random.dirichlet([1,1,1,1],5).tolist(),np.random.dirichlet([1,1,1,1],5).tolist())),\n",
    "                     list(zip(np.random.dirichlet([1,1,1],5).tolist(),np.random.dirichlet([1,1,1],5).tolist())),\n",
    "                     list(zip(np.random.dirichlet([1,1,1,1,1],5).tolist(),np.random.dirichlet([1,1,1,1,1],5).tolist())),\n",
    "                     list(zip(np.random.dirichlet([1,1,1,1,1,1],5).tolist(),np.random.dirichlet([1,1,1,1,1,1],5).tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.6249198216400619, 0.37508017835993795],\n",
       "        [0.3946604132086852, 0.6053395867913146]],\n",
       "       [[0.9820270769942365, 0.017972923005763513],\n",
       "        [0.8890698404664713, 0.1109301595335287]],\n",
       "       [[0.6643670634209644, 0.3356329365790356],\n",
       "        [0.976049914253328, 0.02395008574667222]],\n",
       "       [[0.8807766255007131, 0.11922337449928692],\n",
       "        [0.7401912482273242, 0.2598087517726758]],\n",
       "       [[0.9985355125997742, 0.0014644874002257002],\n",
       "        [0.06487265150286255, 0.9351273484971374]],\n",
       "       [[0.5167704752798782, 0.48322952472012193],\n",
       "        [0.9482168688515075, 0.051783131148492666]],\n",
       "       [[0.41016433506604055, 0.5898356649339594],\n",
       "        [0.42133915624052337, 0.5786608437594766]],\n",
       "       [[0.8401088541206045, 0.1598911458793955],\n",
       "        [0.4723812136551637, 0.5276187863448362]],\n",
       "       [[0.8307499014424404, 0.1692500985575596],\n",
       "        [0.07782291591332545, 0.9221770840866744]],\n",
       "       [[0.05532464958329419, 0.9446753504167058],\n",
       "        [0.6718416659947983, 0.32815833400520156]],\n",
       "       [[0.22738382459255063, 0.7726161754074493],\n",
       "        [0.6272286545128304, 0.3727713454871695]],\n",
       "       [[0.16951597494463866, 0.8304840250553612],\n",
       "        [0.08442669621408619, 0.915573303785914]],\n",
       "       [[0.8754418562842615, 0.12455814371573852],\n",
       "        [0.6064318954749228, 0.3935681045250772]],\n",
       "       [[0.9118907166868147, 0.08810928331318517],\n",
       "        [0.3104936285939414, 0.6895063714060585]],\n",
       "       [[0.8388783917853455, 0.16112160821465446],\n",
       "        [0.9585882162655153, 0.04141178373448465]],\n",
       "       [[0.0994974684488835, 0.1935062018644171, 0.7069963296866993],\n",
       "        [0.21750956549604114, 0.32200857125625326, 0.46048186324770546]],\n",
       "       [[0.4958505350798417, 0.4108446490527296, 0.09330481586742867],\n",
       "        [0.10443438552393379, 0.39898301959943255, 0.49658259487663375]],\n",
       "       [[0.39255229735485375, 0.197359376337018, 0.41008832630812825],\n",
       "        [0.19471188116591281, 0.3417164743424756, 0.46357164449161165]],\n",
       "       [[0.2846618135390535, 0.7117658750181769, 0.0035723114427696195],\n",
       "        [0.2014675712850103, 0.0837746734368037, 0.7147577552781859]],\n",
       "       [[0.14977713454634656, 0.02003899816967307, 0.8301838672839804],\n",
       "        [0.1049889985738408, 0.6594833019386255, 0.2355276994875337]],\n",
       "       [ [0.5654828199008637, 0.21097666270640597, 0.05258505626193287, 0.17095546113079754],\n",
       "        [0.3796175911935445, 0.3356997843425627, 0.2376045764896033, 0.047078047974289564]],\n",
       "       [ [0.10683803058785969, 0.15891875047851373, 0.47139613760592775, 0.26284708132769874],\n",
       "        [0.21616772002337475, 0.23354481708916333, 0.16019357152826008, 0.39009389135920186]],\n",
       "       [ [0.25085837726719384, 0.19195567514309161, 0.2701040555297026, 0.2870818920600119],\n",
       "        [0.04284892687904823, 0.06716993623822973, 0.5654498513808035, 0.3245312855019185]],\n",
       "       [ [0.11450255937257463, 0.04534063926551845, 0.8228927337009636, 0.01726406766094343],\n",
       "        [0.16092750311740417, 0.3280154047467259, 0.33178974053067534, 0.1792673516051946]],\n",
       "       [ [0.17541562159786023, 0.054966521275101994, 0.23149317249948437, 0.5381246846275535],\n",
       "        [0.3676616493792673, 0.09006534743588333, 0.38198848952501663, 0.1602845136598328]],\n",
       "       [[0.3407012443453669, 0.3251770749793909, 0.33412168067524217],\n",
       "        [0.18476806367448798, 0.11701158112455491, 0.6982203552009572]],\n",
       "       [[0.7924312239025622, 0.052208721709395896, 0.15536005438804204],\n",
       "        [0.02092473853022848, 0.8925289890375634, 0.08654627243220823]],\n",
       "       [[0.07369701521600554, 0.7034598796611877, 0.22284310512280678],\n",
       "        [0.01772459887704899, 0.3348785690245104, 0.6473968320984406]],\n",
       "       [[0.060230387392912026, 0.36056143871252755, 0.5792081738945605],\n",
       "        [0.24236061406660853, 0.28983960321059987, 0.46779978272279166]],\n",
       "       [[0.4199551060332194, 0.0425133524911752, 0.5375315414756053],\n",
       "        [0.24882376283642121, 0.17889457941242237, 0.5722816577511565]],\n",
       "       [ [0.20178213547844467, 0.23582358094170927, 0.2549053747570244, 0.25624458090583896, 0.051244327916982704],\n",
       "        [0.010013224030871171, 0.28202192598054376, 0.003616023305951549, 0.6733430485953009, 0.03100577808733252]],\n",
       "       [ [0.017027831417240322, 0.1360238484680724, 0.5518048184468171, 0.25992081928346517, 0.03522268238440502],\n",
       "        [0.03939520529156576, 0.224349131220571, 0.4493715947012436, 0.13712241504394443, 0.14976165374267533]],\n",
       "       [ [0.021383097913350056, 0.2718071063990199, 0.2719783873108702, 0.3486021329750529, 0.08622927540170693],\n",
       "        [0.4596291076645845, 0.18098113925161693, 0.15680254129077528, 0.08828402478892097, 0.11430318700410246]],\n",
       "       [ [0.2164389927951599, 0.43587843288601213, 0.0626879296176134, 0.07527834555286, 0.2097162991483547],\n",
       "        [0.07675174904872409, 0.16250421618712663, 0.2942103012464006, 0.24724912255947887, 0.2192846109582699]],\n",
       "       [ [0.05513584318285564, 0.481770917665183, 0.04027059141541376, 0.09758762268245656, 0.325235025054091],\n",
       "        [0.33879316176844315, 0.25916629483308884, 0.3322442401812106, 0.005516392183658215, 0.06427991103359917]],\n",
       "       [ [0.1155423032495674, 0.08174573784559794, 0.15005101441559474, 0.5772064700722275, 0.021991356663258358, 0.053463117753754244],\n",
       "        [0.24265533207695478, 0.13382175558308043, 0.09820759152372367, 0.433309782087178, 0.044725887112365824, 0.04727965161669716]],\n",
       "       [ [0.47996336701353215, 0.08729466376479686, 0.08464532473997254, 0.3214487931801258, 0.006684374136866367, 0.019963477164706294],\n",
       "        [0.04419995060235569, 0.21334475093396638, 0.30193522718374316, 0.0453506415800753, 0.16831431550474993, 0.22685511419510956]],\n",
       "       [ [0.016925249475587587, 0.5693842363615218, 0.011699075496366111, 0.0643388810483932, 0.2770696092682656, 0.06058294834986565],\n",
       "        [0.396351735476584, 0.32930178948425765, 0.010720098902934308, 0.04625205691115544, 0.1343083441392843, 0.08306597508578431]],\n",
       "       [ [0.00919358428028653, 0.20747920140171133, 0.03339837121186943, 0.34122023576895416, 0.2405560276532923, 0.1681525796838864],\n",
       "        [0.2069360430021255, 0.3302244053320049, 0.07452659856437703, 0.20398359602819074, 0.17281882367453633, 0.01151053339876546]],\n",
       "       [ [0.18576773811652167, 0.23683088991352966, 0.06715490954016586, 0.058266063537867695, 0.2449937590987011, 0.20698663979321402],\n",
       "        [0.22776584076779455, 0.010906997108758103, 0.054400103835779055, 0.024363743760675613, 0.05495635783042389, 0.6276069566965687]]], dtype=object)"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi=np.array(list(ab))\n",
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.6249198216400619, 0.37508017835993795],\n",
       "        [0.3946604132086852, 0.6053395867913146]],\n",
       "       [[0.41016433506604055, 0.5898356649339594],\n",
       "        [0.42133915624052337, 0.5786608437594766]],\n",
       "       [[0.22738382459255063, 0.7726161754074493],\n",
       "        [0.6272286545128304, 0.3727713454871695]],\n",
       "       [[0.8754418562842615, 0.12455814371573852],\n",
       "        [0.6064318954749228, 0.3935681045250772]],\n",
       "       [ [0.00919358428028653, 0.20747920140171133, 0.03339837121186943, 0.34122023576895416, 0.2405560276532923, 0.1681525796838864],\n",
       "        [0.2069360430021255, 0.3302244053320049, 0.07452659856437703, 0.20398359602819074, 0.17281882367453633, 0.01151053339876546]],\n",
       "       [[0.5167704752798782, 0.48322952472012193],\n",
       "        [0.9482168688515075, 0.051783131148492666]],\n",
       "       [[0.16951597494463866, 0.8304840250553612],\n",
       "        [0.08442669621408619, 0.915573303785914]],\n",
       "       [ [0.11450255937257463, 0.04534063926551845, 0.8228927337009636, 0.01726406766094343],\n",
       "        [0.16092750311740417, 0.3280154047467259, 0.33178974053067534, 0.1792673516051946]],\n",
       "       [[0.9820270769942365, 0.017972923005763513],\n",
       "        [0.8890698404664713, 0.1109301595335287]],\n",
       "       [[0.9118907166868147, 0.08810928331318517],\n",
       "        [0.3104936285939414, 0.6895063714060585]],\n",
       "       [ [0.5654828199008637, 0.21097666270640597, 0.05258505626193287, 0.17095546113079754],\n",
       "        [0.3796175911935445, 0.3356997843425627, 0.2376045764896033, 0.047078047974289564]]], dtype=object)"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi[np.append(0,vars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.83963133e-10,   1.00000000e+00],\n",
       "       [  1.09922548e-04,   9.99890077e-01],\n",
       "       [  5.44714744e-07,   9.99999455e-01],\n",
       "       [  7.59398447e-02,   9.24060155e-01],\n",
       "       [  1.19911030e-06,   9.99998801e-01],\n",
       "       [  1.73448720e-06,   9.99998266e-01],\n",
       "       [  4.01973309e-02,   9.59802669e-01],\n",
       "       [  1.73903029e-04,   9.99826097e-01],\n",
       "       [  8.06482400e-09,   9.99999992e-01],\n",
       "       [  4.74146069e-01,   5.25853931e-01]])"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(121)\n",
    "alpha=np.random.dirichlet((0.1, 2), 10)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.multinomial(1,alpha[4],1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0]"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles=[]\n",
    "np.random.seed(121)\n",
    "for i in range(10):\n",
    "    profiles.append(np.random.multinomial(1,alpha[i],1)[0][1])\n",
    "profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=np.zeros(40)\n",
    "for i in range(1000):\n",
    "    cd=itertools.chain(np.random.choice(2,15).tolist(),np.random.choice(3,5).tolist(),np.random.choice(4,5).tolist(),\n",
    "                   np.random.choice(3,5).tolist(),np.random.choice(5,5).tolist(),np.random.choice(6,5))\n",
    "    cd=np.array(list(cd))\n",
    "    real_data=[]\n",
    "    for i in range(10):\n",
    "        real_data.append(np.where(np.random.multinomial(1, phi[vars][i][profiles[i]], size=1)==1)[1].tolist())\n",
    "    real_data=sum(real_data,[])\n",
    "    \n",
    "    y=np.vstack([y,np.array(list(cd))])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 40)"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=np.delete(y,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=np.transpose(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 1000)"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=y[vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def profile_class(data,phi,NumProf):\n",
    "    \"\"\"This function calculates the GoM scores for each individual\n",
    "        Parameters:\n",
    "        Input: data and phi calculate from MELD\n",
    "           Output: GoM score\n",
    "        \"\"\"\n",
    "    score=np.zeros([data.shape[1],NumProf])\n",
    "    profile=np.zeros([int(data.shape[0]),int(data.shape[1])])\n",
    "    for j in range(data.shape[1]):\n",
    "        for i in range(data.shape[0]):\n",
    "            yij=int(data[i,j])\n",
    "            #calculate M_ij\n",
    "            profile[i,j]=np.argmax(np.array(list(phi[i]))[:,yij])\n",
    "            if profile[i,j]==0:\n",
    "                score[j,0]=score[j,0]+1\n",
    "            else:\n",
    "                score[j,1]=score[j,1]+1\n",
    "        score[j,:]=(score[j,:]+0.1)/(phi.shape[0]+0.2)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi[np.append(0,vars)][1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51278433,  0.53535879,  0.51278433,  0.51278433,  0.49020988,\n",
       "        0.55793324,  0.49020988,  0.51278433,  0.46763543,  0.46763543,\n",
       "        0.51278433,  0.51278433,  0.46763543,  0.49020988,  0.44506098,\n",
       "        0.53535879,  0.46763543,  0.49020988,  0.51278433,  0.55793324,\n",
       "        0.49020988,  0.51278433,  0.44506098,  0.46763543,  0.51278433,\n",
       "        0.46763543,  0.49020988,  0.51278433,  0.53535879,  0.53535879,\n",
       "        0.51278433,  0.51278433,  0.46763543,  0.46763543,  0.46763543,\n",
       "        0.46763543,  0.49020988,  0.44506098,  0.46763543,  0.46763543,\n",
       "        0.53535879,  0.55793324,  0.53535879,  0.51278433,  0.46763543,\n",
       "        0.51278433,  0.49020988,  0.46763543,  0.55793324,  0.51278433,\n",
       "        0.46763543,  0.53535879,  0.44506098,  0.51278433,  0.51278433,\n",
       "        0.46763543,  0.46763543,  0.46763543,  0.44506098,  0.51278433,\n",
       "        0.53535879,  0.44506098,  0.55793324,  0.51278433,  0.44506098,\n",
       "        0.51278433,  0.49020988,  0.51278433,  0.44506098,  0.51278433,\n",
       "        0.42248653,  0.49020988,  0.49020988,  0.51278433,  0.55793324,\n",
       "        0.49020988,  0.53535879,  0.49020988,  0.46763543,  0.44506098,\n",
       "        0.53535879,  0.49020988,  0.49020988,  0.51278433,  0.51278433,\n",
       "        0.51278433,  0.55793324,  0.53535879,  0.46763543,  0.51278433,\n",
       "        0.49020988,  0.46763543,  0.53535879,  0.44506098,  0.51278433,\n",
       "        0.44506098,  0.46763543,  0.51278433,  0.49020988,  0.53535879,\n",
       "        0.49020988,  0.53535879,  0.46763543,  0.55793324,  0.46763543,\n",
       "        0.53535879,  0.46763543,  0.49020988,  0.44506098,  0.53535879,\n",
       "        0.46763543,  0.49020988,  0.49020988,  0.46763543,  0.49020988,\n",
       "        0.51278433,  0.55793324,  0.46763543,  0.42248653,  0.46763543,\n",
       "        0.53535879,  0.49020988,  0.53535879,  0.49020988,  0.53535879,\n",
       "        0.53535879,  0.53535879,  0.49020988,  0.49020988,  0.44506098,\n",
       "        0.51278433,  0.51278433,  0.46763543,  0.46763543,  0.46763543,\n",
       "        0.55793324,  0.46763543,  0.51278433,  0.55793324,  0.44506098,\n",
       "        0.46763543,  0.55793324,  0.49020988,  0.51278433,  0.51278433,\n",
       "        0.51278433,  0.51278433,  0.55793324,  0.49020988,  0.51278433,\n",
       "        0.49020988,  0.44506098,  0.46763543,  0.55793324,  0.49020988,\n",
       "        0.51278433,  0.44506098,  0.49020988,  0.49020988,  0.49020988,\n",
       "        0.49020988,  0.46763543,  0.44506098,  0.46763543,  0.49020988,\n",
       "        0.53535879,  0.46763543,  0.46763543,  0.51278433,  0.51278433,\n",
       "        0.44506098,  0.46763543,  0.49020988,  0.46763543,  0.46763543,\n",
       "        0.51278433,  0.51278433,  0.53535879,  0.51278433,  0.58050769,\n",
       "        0.49020988,  0.51278433,  0.44506098,  0.46763543,  0.44506098,\n",
       "        0.46763543,  0.46763543,  0.44506098,  0.46763543,  0.53535879,\n",
       "        0.51278433,  0.46763543,  0.53535879,  0.51278433,  0.49020988,\n",
       "        0.49020988,  0.51278433,  0.53535879,  0.46763543,  0.44506098,\n",
       "        0.42248653,  0.51278433,  0.49020988,  0.44506098,  0.51278433,\n",
       "        0.51278433,  0.51278433,  0.55793324,  0.49020988,  0.46763543,\n",
       "        0.51278433,  0.58050769,  0.46763543,  0.58050769,  0.49020988,\n",
       "        0.44506098,  0.53535879,  0.51278433,  0.51278433,  0.53535879,\n",
       "        0.49020988,  0.53535879,  0.53535879,  0.51278433,  0.44506098,\n",
       "        0.51278433,  0.49020988,  0.53535879,  0.44506098,  0.46763543,\n",
       "        0.46763543,  0.51278433,  0.51278433,  0.53535879,  0.46763543,\n",
       "        0.51278433,  0.53535879,  0.49020988,  0.42248653,  0.51278433,\n",
       "        0.46763543,  0.44506098,  0.53535879,  0.46763543,  0.55793324,\n",
       "        0.51278433,  0.44506098,  0.44506098,  0.58050769,  0.44506098,\n",
       "        0.46763543,  0.51278433,  0.55793324,  0.53535879,  0.49020988,\n",
       "        0.51278433,  0.46763543,  0.51278433,  0.53535879,  0.53535879,\n",
       "        0.49020988,  0.49020988,  0.49020988,  0.51278433,  0.53535879,\n",
       "        0.46763543,  0.51278433,  0.49020988,  0.49020988,  0.53535879,\n",
       "        0.46763543,  0.51278433,  0.55793324,  0.46763543,  0.46763543,\n",
       "        0.53535879,  0.51278433,  0.51278433,  0.49020988,  0.51278433,\n",
       "        0.46763543,  0.55793324,  0.44506098,  0.51278433,  0.51278433,\n",
       "        0.51278433,  0.49020988,  0.46763543,  0.46763543,  0.44506098,\n",
       "        0.51278433,  0.51278433,  0.53535879,  0.53535879,  0.42248653,\n",
       "        0.51278433,  0.44506098,  0.46763543,  0.49020988,  0.49020988,\n",
       "        0.49020988,  0.46763543,  0.49020988,  0.46763543,  0.49020988,\n",
       "        0.46763543,  0.49020988,  0.49020988,  0.42248653,  0.49020988,\n",
       "        0.53535879,  0.46763543,  0.46763543,  0.58050769,  0.49020988,\n",
       "        0.51278433,  0.46763543,  0.55793324,  0.49020988,  0.51278433,\n",
       "        0.55793324,  0.49020988,  0.46763543,  0.51278433,  0.49020988,\n",
       "        0.51278433,  0.51278433,  0.49020988,  0.44506098,  0.42248653,\n",
       "        0.44506098,  0.51278433,  0.55793324,  0.55793324,  0.46763543,\n",
       "        0.53535879,  0.46763543,  0.39991208,  0.49020988,  0.55793324,\n",
       "        0.53535879,  0.46763543,  0.44506098,  0.51278433,  0.51278433,\n",
       "        0.46763543,  0.55793324,  0.53535879,  0.53535879,  0.46763543,\n",
       "        0.51278433,  0.51278433,  0.55793324,  0.53535879,  0.49020988,\n",
       "        0.51278433,  0.51278433,  0.46763543,  0.49020988,  0.46763543,\n",
       "        0.46763543,  0.46763543,  0.51278433,  0.46763543,  0.49020988,\n",
       "        0.44506098,  0.51278433,  0.49020988,  0.51278433,  0.44506098,\n",
       "        0.53535879,  0.53535879,  0.55793324,  0.44506098,  0.49020988,\n",
       "        0.51278433,  0.49020988,  0.53535879,  0.49020988,  0.46763543,\n",
       "        0.53535879,  0.53535879,  0.53535879,  0.42248653,  0.51278433,\n",
       "        0.49020988,  0.51278433,  0.44506098,  0.42248653,  0.49020988,\n",
       "        0.49020988,  0.49020988,  0.51278433,  0.46763543,  0.46763543,\n",
       "        0.44506098,  0.49020988,  0.53535879,  0.51278433,  0.46763543,\n",
       "        0.46763543,  0.46763543,  0.53535879,  0.53535879,  0.49020988,\n",
       "        0.44506098,  0.53535879,  0.53535879,  0.51278433,  0.49020988,\n",
       "        0.46763543,  0.46763543,  0.51278433,  0.53535879,  0.51278433,\n",
       "        0.49020988,  0.46763543,  0.46763543,  0.49020988,  0.44506098,\n",
       "        0.51278433,  0.51278433,  0.44506098,  0.44506098,  0.55793324,\n",
       "        0.44506098,  0.49020988,  0.44506098,  0.51278433,  0.46763543,\n",
       "        0.51278433,  0.46763543,  0.53535879,  0.49020988,  0.51278433,\n",
       "        0.53535879,  0.46763543,  0.53535879,  0.51278433,  0.51278433,\n",
       "        0.51278433,  0.49020988,  0.51278433,  0.53535879,  0.46763543,\n",
       "        0.51278433,  0.44506098,  0.51278433,  0.49020988,  0.53535879,\n",
       "        0.53535879,  0.44506098,  0.49020988,  0.44506098,  0.49020988,\n",
       "        0.51278433,  0.51278433,  0.46763543,  0.55793324,  0.51278433,\n",
       "        0.46763543,  0.53535879,  0.44506098,  0.55793324,  0.51278433,\n",
       "        0.51278433,  0.49020988,  0.46763543,  0.53535879,  0.49020988,\n",
       "        0.51278433,  0.44506098,  0.55793324,  0.51278433,  0.49020988,\n",
       "        0.53535879,  0.46763543,  0.46763543,  0.42248653,  0.53535879,\n",
       "        0.51278433,  0.46763543,  0.46763543,  0.53535879,  0.44506098,\n",
       "        0.46763543,  0.49020988,  0.46763543,  0.49020988,  0.44506098,\n",
       "        0.51278433,  0.44506098,  0.46763543,  0.49020988,  0.53535879,\n",
       "        0.51278433,  0.53535879,  0.46763543,  0.51278433,  0.55793324,\n",
       "        0.55793324,  0.44506098,  0.46763543,  0.46763543,  0.49020988,\n",
       "        0.49020988,  0.53535879,  0.49020988,  0.46763543,  0.49020988,\n",
       "        0.46763543,  0.46763543,  0.46763543,  0.53535879,  0.51278433,\n",
       "        0.51278433,  0.42248653,  0.46763543,  0.53535879,  0.46763543,\n",
       "        0.53535879,  0.49020988,  0.49020988,  0.53535879,  0.55793324,\n",
       "        0.49020988,  0.51278433,  0.53535879,  0.53535879,  0.51278433,\n",
       "        0.51278433,  0.46763543,  0.51278433,  0.55793324,  0.51278433,\n",
       "        0.46763543,  0.51278433,  0.51278433,  0.46763543,  0.51278433,\n",
       "        0.53535879,  0.49020988,  0.46763543,  0.44506098,  0.51278433,\n",
       "        0.51278433,  0.44506098,  0.46763543,  0.49020988,  0.49020988,\n",
       "        0.44506098,  0.51278433,  0.51278433,  0.49020988,  0.58050769,\n",
       "        0.51278433,  0.55793324,  0.51278433,  0.49020988,  0.53535879,\n",
       "        0.49020988,  0.49020988,  0.53535879,  0.49020988,  0.51278433,\n",
       "        0.49020988,  0.46763543,  0.49020988,  0.46763543,  0.53535879,\n",
       "        0.49020988,  0.49020988,  0.55793324,  0.46763543,  0.44506098,\n",
       "        0.46763543,  0.51278433,  0.46763543,  0.46763543,  0.51278433,\n",
       "        0.53535879,  0.51278433,  0.42248653,  0.55793324,  0.44506098,\n",
       "        0.44506098,  0.49020988,  0.46763543,  0.44506098,  0.51278433,\n",
       "        0.46763543,  0.53535879,  0.51278433,  0.51278433,  0.44506098,\n",
       "        0.46763543,  0.49020988,  0.53535879,  0.53535879,  0.58050769,\n",
       "        0.55793324,  0.53535879,  0.53535879,  0.51278433,  0.46763543,\n",
       "        0.46763543,  0.46763543,  0.49020988,  0.51278433,  0.51278433,\n",
       "        0.46763543,  0.46763543,  0.53535879,  0.51278433,  0.49020988,\n",
       "        0.44506098,  0.49020988,  0.53535879,  0.53535879,  0.46763543,\n",
       "        0.53535879,  0.51278433,  0.53535879,  0.53535879,  0.51278433,\n",
       "        0.53535879,  0.55793324,  0.53535879,  0.49020988,  0.53535879,\n",
       "        0.53535879,  0.51278433,  0.53535879,  0.42248653,  0.46763543,\n",
       "        0.55793324,  0.53535879,  0.58050769,  0.49020988,  0.49020988,\n",
       "        0.49020988,  0.46763543,  0.55793324,  0.51278433,  0.51278433,\n",
       "        0.49020988,  0.49020988,  0.53535879,  0.51278433,  0.46763543,\n",
       "        0.46763543,  0.49020988,  0.49020988,  0.51278433,  0.42248653,\n",
       "        0.46763543,  0.55793324,  0.53535879,  0.49020988,  0.49020988,\n",
       "        0.46763543,  0.49020988,  0.49020988,  0.53535879,  0.53535879,\n",
       "        0.46763543,  0.49020988,  0.49020988,  0.44506098,  0.44506098,\n",
       "        0.46763543,  0.46763543,  0.49020988,  0.46763543,  0.42248653,\n",
       "        0.51278433,  0.46763543,  0.53535879,  0.49020988,  0.46763543,\n",
       "        0.46763543,  0.42248653,  0.49020988,  0.55793324,  0.51278433,\n",
       "        0.49020988,  0.55793324,  0.46763543,  0.42248653,  0.58050769,\n",
       "        0.49020988,  0.51278433,  0.46763543,  0.53535879,  0.44506098,\n",
       "        0.51278433,  0.44506098,  0.49020988,  0.53535879,  0.51278433,\n",
       "        0.42248653,  0.46763543,  0.53535879,  0.51278433,  0.42248653,\n",
       "        0.49020988,  0.39991208,  0.49020988,  0.44506098,  0.55793324,\n",
       "        0.46763543,  0.53535879,  0.51278433,  0.51278433,  0.55793324,\n",
       "        0.46763543,  0.39991208,  0.46763543,  0.51278433,  0.44506098,\n",
       "        0.55793324,  0.49020988,  0.46763543,  0.46763543,  0.53535879,\n",
       "        0.46763543,  0.49020988,  0.51278433,  0.53535879,  0.53535879,\n",
       "        0.51278433,  0.53535879,  0.49020988,  0.53535879,  0.49020988,\n",
       "        0.49020988,  0.51278433,  0.53535879,  0.44506098,  0.49020988,\n",
       "        0.49020988,  0.53535879,  0.46763543,  0.51278433,  0.55793324,\n",
       "        0.46763543,  0.53535879,  0.46763543,  0.49020988,  0.49020988,\n",
       "        0.46763543,  0.46763543,  0.46763543,  0.42248653,  0.51278433,\n",
       "        0.53535879,  0.49020988,  0.49020988,  0.44506098,  0.51278433,\n",
       "        0.49020988,  0.51278433,  0.46763543,  0.55793324,  0.55793324,\n",
       "        0.53535879,  0.46763543,  0.49020988,  0.49020988,  0.46763543,\n",
       "        0.44506098,  0.51278433,  0.53535879,  0.55793324,  0.53535879,\n",
       "        0.46763543,  0.53535879,  0.51278433,  0.46763543,  0.46763543,\n",
       "        0.49020988,  0.51278433,  0.46763543,  0.49020988,  0.49020988,\n",
       "        0.49020988,  0.51278433,  0.55793324,  0.49020988,  0.49020988,\n",
       "        0.55793324,  0.49020988,  0.46763543,  0.51278433,  0.49020988,\n",
       "        0.53535879,  0.55793324,  0.53535879,  0.49020988,  0.49020988,\n",
       "        0.53535879,  0.44506098,  0.53535879,  0.55793324,  0.44506098,\n",
       "        0.46763543,  0.53535879,  0.53535879,  0.44506098,  0.46763543,\n",
       "        0.49020988,  0.46763543,  0.51278433,  0.51278433,  0.51278433,\n",
       "        0.51278433,  0.46763543,  0.51278433,  0.53535879,  0.53535879,\n",
       "        0.49020988,  0.51278433,  0.53535879,  0.46763543,  0.55793324,\n",
       "        0.42248653,  0.49020988,  0.46763543,  0.49020988,  0.55793324,\n",
       "        0.58050769,  0.55793324,  0.44506098,  0.46763543,  0.55793324,\n",
       "        0.46763543,  0.51278433,  0.49020988,  0.46763543,  0.53535879,\n",
       "        0.51278433,  0.55793324,  0.46763543,  0.49020988,  0.42248653,\n",
       "        0.49020988,  0.58050769,  0.49020988,  0.49020988,  0.49020988,\n",
       "        0.51278433,  0.46763543,  0.49020988,  0.53535879,  0.44506098,\n",
       "        0.46763543,  0.49020988,  0.51278433,  0.46763543,  0.46763543,\n",
       "        0.51278433,  0.53535879,  0.53535879,  0.51278433,  0.53535879,\n",
       "        0.49020988,  0.49020988,  0.49020988,  0.49020988,  0.49020988,\n",
       "        0.51278433,  0.49020988,  0.46763543,  0.55793324,  0.46763543,\n",
       "        0.46763543,  0.51278433,  0.51278433,  0.53535879,  0.53535879,\n",
       "        0.51278433,  0.51278433,  0.55793324,  0.51278433,  0.46763543,\n",
       "        0.46763543,  0.53535879,  0.51278433,  0.46763543,  0.51278433,\n",
       "        0.42248653,  0.46763543,  0.44506098,  0.51278433,  0.49020988,\n",
       "        0.49020988,  0.46763543,  0.53535879,  0.51278433,  0.49020988,\n",
       "        0.53535879,  0.44506098,  0.51278433,  0.44506098,  0.53535879,\n",
       "        0.53535879,  0.49020988,  0.49020988,  0.51278433,  0.39991208,\n",
       "        0.51278433,  0.49020988,  0.51278433,  0.53535879,  0.53535879,\n",
       "        0.49020988,  0.51278433,  0.51278433,  0.49020988,  0.49020988,\n",
       "        0.44506098,  0.49020988,  0.39991208,  0.46763543,  0.49020988,\n",
       "        0.51278433,  0.49020988,  0.46763543,  0.44506098,  0.55793324,\n",
       "        0.53535879,  0.53535879,  0.46763543,  0.46763543,  0.46763543,\n",
       "        0.51278433,  0.49020988,  0.49020988,  0.44506098,  0.46763543,\n",
       "        0.51278433,  0.49020988,  0.46763543,  0.46763543,  0.49020988,\n",
       "        0.55793324,  0.49020988,  0.51278433,  0.49020988,  0.49020988,\n",
       "        0.51278433,  0.46763543,  0.49020988,  0.51278433,  0.51278433,\n",
       "        0.49020988,  0.51278433,  0.49020988,  0.44506098,  0.51278433,\n",
       "        0.49020988,  0.49020988,  0.46763543,  0.53535879,  0.46763543,\n",
       "        0.46763543,  0.49020988,  0.46763543,  0.44506098,  0.51278433,\n",
       "        0.53535879,  0.49020988,  0.46763543,  0.49020988,  0.49020988,\n",
       "        0.53535879,  0.46763543,  0.42248653,  0.49020988,  0.53535879,\n",
       "        0.51278433,  0.46763543,  0.44506098,  0.53535879,  0.49020988,\n",
       "        0.46763543,  0.46763543,  0.46763543,  0.44506098,  0.44506098,\n",
       "        0.46763543,  0.46763543,  0.46763543,  0.46763543,  0.51278433,\n",
       "        0.53535879,  0.49020988,  0.53535879,  0.44506098,  0.46763543])"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscore=profile_class(test,phi[vars],2)\n",
    "# calculate risk\n",
    "risk=gscore[:,None]*np.transpose(np.array(list(phi[0])))\n",
    "risk=np.sum(risk[:,1,:],axis=1)\n",
    "risk\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.place(risk,risk<0.5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.place(risk,risk>=0.5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,\n",
       "        0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,\n",
       "        0.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,\n",
       "        1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
       "        0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,\n",
       "        0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,\n",
       "        1.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
       "        1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,\n",
       "        0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,\n",
       "        0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,\n",
       "        1.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,\n",
       "        0.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,\n",
       "        0.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,\n",
       "        0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,\n",
       "        0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,\n",
       "        0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
       "        1.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,\n",
       "        0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,\n",
       "        1.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
       "        1.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,\n",
       "        1.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,\n",
       "        0.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  0.,\n",
       "        1.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
       "        1.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,\n",
       "        1.,  0.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,\n",
       "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "        1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
       "        1.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,\n",
       "        1.,  1.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  0.,\n",
       "        1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,\n",
       "        0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,\n",
       "        1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
       "        0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,\n",
       "        1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "        1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,\n",
       "        0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,\n",
       "        1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,\n",
       "        1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
       "        1.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,\n",
       "        1.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,  1.,\n",
       "        1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,\n",
       "        0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "        1.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
       "        1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
       "        0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
       "        1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y[0]=risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MELD_Backward_features(data, Numfolds, features, NumProf):\n",
    "    \"\"\"This function performs supervised MELD and backward elimination algorithm\n",
    "    Parameters:\n",
    "        Input: a dataframe and number of folds\n",
    "        output: select maximum AUC and corresponding features \n",
    "        for every specific number of features  \n",
    "    \"\"\"\n",
    "    #divide data into kf cross validation folds\n",
    "    kf=KFold(data.shape[1],Numfolds,shuffle=False,random_state=111)\n",
    "    \n",
    "    def profile_class(data,phi):\n",
    "        \"\"\"This function calculates the GoM scores for each individual\n",
    "        Parameters:\n",
    "        Input: data and phi calculate from MELD\n",
    "           Output: GoM score\n",
    "        \"\"\"\n",
    "        score=np.zeros([data.shape[1],NumProf])\n",
    "        profile=np.zeros([int(data.shape[0]),int(data.shape[1])])\n",
    "        for j in range(data.shape[1]):\n",
    "            for i in range(data.shape[0]):\n",
    "                yij=int(data[i,j])\n",
    "                #calculate M_ij\n",
    "                profile[i,j]=np.argmax(phi[i][:,yij])\n",
    "                if profile[i,j]==0:\n",
    "                    score[j,0]=score[j,0]+1\n",
    "                else:\n",
    "                    score[j,1]=score[j,1]+1\n",
    "            score[j,:]=(score[j,:]+0.1)/(phi.shape[0]+0.1*NumProf)\n",
    "        return score\n",
    "    \n",
    "    #create a list of features\n",
    "    vec_list=[]\n",
    "    for j in range(len(features)-1):\n",
    "        integers=features[:]\n",
    "        del integers[j+1]\n",
    "        vec_list.append(integers)\n",
    "    \n",
    "    auc_list_outer=[]\n",
    "    #whole_gom_list=[]\n",
    "    for j in range(len(vec_list)):\n",
    "        auc_list=[]\n",
    "        #gom_list=[]\n",
    "        vec=vec_list[j]\n",
    "        for i in range(Numfolds):\n",
    "            train=data[:,list(kf)[i][0]]\n",
    "            test=data[:,list(kf)[i][1]]\n",
    "            import sim as MELD\n",
    "            k=NumProf\n",
    "            S=100\n",
    "            Y = train\n",
    "            (p,n) = Y.shape\n",
    "            Yt = np.array([0]*p)\n",
    "            Yt[0]=0\n",
    "            # create an object of MELD class\n",
    "            myMELD = MELD.MELD(Y,Yt,k,vec)\n",
    "            # calculate second moment matrices\n",
    "            myMELD.calM2()\n",
    "            myMELD.calM2_bar()\n",
    "            # ------------- first stage\n",
    "            # initialize weight matrices to identity\n",
    "            myMELD.initializeWeight_M2()\n",
    "            # perform first stage estimation\n",
    "            Result1 = myMELD.estimatePhiGrad_M2(S)\n",
    "            # extract phi from the result\n",
    "            phi1=Result1['PHI'][Result1['iter']]\n",
    "            # extract selected features in the test fold\n",
    "            test=test[vec]\n",
    "            # calculate GoM score\n",
    "            gscore=profile_class(test[1:],phi1[1:])\n",
    "            # calculate risk\n",
    "            risk=gscore[:,None]*np.transpose(phi1[0])\n",
    "            risk=np.sum(risk[:,1,:],axis=1)\n",
    "            #gom_list.append(gscore[:,1])\n",
    "            # replace 0 with label \"-1\"\n",
    "            np.place(test[0],test[0]==0,[-1])\n",
    "            # calculate AUC\n",
    "            auc = roc_auc_score(test[0],risk)\n",
    "            auc_list.append(auc)\n",
    "        #calculate the mean AUC across kf folds\n",
    "        auc_new=np.mean(auc_list)\n",
    "        auc_list_outer.append(auc_new)\n",
    "        #whole_gom_list.append(list(np.concatenate(gom_list)))\n",
    "        \n",
    "    auc_all=[]\n",
    "    vec_all=[]\n",
    "    #gom_all=[]\n",
    "    while len(vec_list)>2:\n",
    "        vec_list_2=vec_list[np.argmax(auc_list_outer).astype(int)] \n",
    "        #gom_list_2=whole_gom_list[np.argmax(auc_list_outer).astype(int)]\n",
    "        vec_all.append(vec_list_2)\n",
    "        #gom_all.append(gom_list_2)\n",
    "        vec_list=[]\n",
    "        #whole_gom_list=[]\n",
    "        #eliminate one feature at a time\n",
    "        for k in range(len(vec_list_2)-1):\n",
    "            integers=vec_list_2[:]\n",
    "            del integers[k+1]\n",
    "            vec_list.append(integers)\n",
    "\n",
    "        auc_list_outer=[] \n",
    "       \n",
    "        for j in range(len(vec_list)):\n",
    "            auc_list=[]\n",
    "            #gom_list=[]\n",
    "            vec=vec_list[j]\n",
    "\n",
    "            for i in range(10):\n",
    "            \n",
    "                train=data[:,list(kf)[i][0]]\n",
    "    \n",
    "                test=data[:,list(kf)[i][1]]\n",
    "        \n",
    "                import sim as MELD\n",
    "                k=NumProf\n",
    "                S=100\n",
    "\n",
    "                Y = train\n",
    "                (p,n) = Y.shape\n",
    "\n",
    "                Yt = np.array([0]*p)\n",
    "                Yt[0]=0\n",
    "                # create an object of MELD class\n",
    "                myMELD = MELD.MELD(Y,Yt,k,vec)\n",
    "\n",
    "                # calculate second moment matrices\n",
    "                myMELD.calM2()\n",
    "                myMELD.calM2_bar()\n",
    "\n",
    "                # ------------- first stage\n",
    "                # initialize weight matrices to identity\n",
    "                myMELD.initializeWeight_M2()\n",
    "\n",
    "                # perform first stage estimation\n",
    "                Result1 = myMELD.estimatePhiGrad_M2(S)\n",
    "                # extract phi from the result\n",
    "                phi1=Result1['PHI'][Result1['iter']]\n",
    "                # extract selected features from test fold\n",
    "                test=test[vec]\n",
    "                # calculate GoM score\n",
    "                gscore=profile_class(test[1:],phi1[1:])\n",
    "                # calculate risk\n",
    "                risk=gscore[:,None]*np.transpose(phi1[0])\n",
    "                risk=np.sum(risk[:,1,:],axis=1)\n",
    "                #gom_list.append(gscore[:,1])\n",
    "                # replace 0 with label \"-1\"\n",
    "                np.place(test[0],test[0]==0,[-1])\n",
    "                # calculate AUC\n",
    "                auc = roc_auc_score(test[0],risk)\n",
    "                auc_list.append(auc)\n",
    "            # calculate average AUC across kf folds\n",
    "            auc_new=np.mean(auc_list)     \n",
    "            auc_list_outer.append(auc_new)\n",
    "            #whole_gom_list.append(list(np.concatenate(gom_list)))\n",
    "              \n",
    "        \n",
    "        # selected the maximum AUC from a list of AUC's\n",
    "        auc_new_new=max(auc_list_outer)\n",
    "    \n",
    "        auc_all.append(auc_new_new)\n",
    "        \n",
    "        auc=np.max(auc_all)\n",
    "        \n",
    "        feature_selected=vec_all[np.argmax(auc_all)]\n",
    "        \n",
    "        #gom=gom_all[np.argmax(auc_all)]\n",
    "    \n",
    "    return auc, feature_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wsswemily/Desktop/SMELD/sim.py:70: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  Y_j = np.zeros((n,self.d[j]))\n",
      "/Users/wsswemily/Desktop/SMELD/sim.py:72: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  Y_j[i,Y[j,i]] = 1\n",
      "/Users/wsswemily/Desktop/SMELD/sim.py:74: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.Phi[j] = np.zeros((k,self.d[j]))\n",
      "/Users/wsswemily/Desktop/SMELD/sim.py:75: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.X[j] = np.zeros((k,self.d[j]))\n",
      "/Users/wsswemily/Desktop/SMELD/sim.py:82: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  self.Phi[j][h,:] = np.random.dirichlet([100.0]*self.d[j])\n",
      "/Users/wsswemily/Desktop/SMELD/sim.py:95: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  M1_j = np.zeros(self.d[j])\n",
      "/Applications/anaconda/lib/python3.5/site-packages/numpy/core/numeric.py:190: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  a = empty(shape, dtype, order)\n",
      "/Users/wsswemily/Desktop/SMELD/sim.py:336: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  a2_jh = np.zeros(d[j])\n",
      "/Users/wsswemily/Desktop/SMELD/sim.py:337: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  b2_jh = np.zeros(d[j])\n",
      "/Users/wsswemily/Desktop/SMELD/sim.py:380: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  Phi_j = np.zeros((k,self.d[j]))\n"
     ]
    }
   ],
   "source": [
    "out_2=MELD_Backward_features(y, 10, list(range(y.shape[0])), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.76557518453482576, [0, 6, 12, 13, 20])"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2  #400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 10, 12, 38,  5, 11, 23,  1, 13, 20])"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res=risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.transpose(y[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 39)"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Applications/anaconda/lib/python3.5/site-packages/slda/_topic_models.cpython-35m-darwin.so, 2): Library not loaded: @rpath/libgsl.19.dylib\n  Referenced from: /Applications/anaconda/lib/python3.5/site-packages/slda/_topic_models.cpython-35m-darwin.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-0ec718c54fb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mslda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mslda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBLSLDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/slda/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtopic_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLDA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSLDA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBLSLDA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGRTM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/slda/topic_models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m from ._topic_models import (gibbs_sampler_lda, gibbs_sampler_slda,\n\u001b[0m\u001b[1;32m     11\u001b[0m                             \u001b[0mgibbs_sampler_blslda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgibbs_sampler_grtm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                             \u001b[0mgibbs_sampler_rtm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgibbs_sampler_blhslda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Applications/anaconda/lib/python3.5/site-packages/slda/_topic_models.cpython-35m-darwin.so, 2): Library not loaded: @rpath/libgsl.19.dylib\n  Referenced from: /Applications/anaconda/lib/python3.5/site-packages/slda/_topic_models.cpython-35m-darwin.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "import slda\n",
    "from slda.topic_models import BLSLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-8a50901ab10b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m_K\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0m_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_nu2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alpha' is not defined"
     ]
    }
   ],
   "source": [
    "_K = 2\n",
    "_alpha = alpha\n",
    "_beta = np.repeat(0.01, V)\n",
    "_mu = 0\n",
    "_nu2 = 0.1\n",
    "_b = 7.25\n",
    "n_iter = 500\n",
    "blslda = BLSLDA(_K, _alpha, _beta, _mu, _nu2, _b, n_iter, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
